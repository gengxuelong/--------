{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "torch.__version__\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0753,  0.1815, -0.1812, -0.0054,  0.2334, -0.0130, -0.0685,  0.0698,\n",
      "          0.1198, -0.1576],\n",
      "        [-0.1133,  0.0458, -0.1501,  0.0498,  0.2123, -0.0960, -0.0562,  0.0230,\n",
      "          0.1341,  0.0570]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.nn import functional as F \n",
    "net = nn.Sequential(nn.Linear(20,256),nn.ReLU(),nn.Linear(256,10))\n",
    "X = torch.rand(2,20)\n",
    "print(net(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2161, -0.1708,  0.0190,  0.0539,  0.0474, -0.1362, -0.1699,  0.1086,\n",
      "         -0.0803,  0.2041],\n",
      "        [ 0.2866, -0.1707, -0.0197,  0.1495,  0.1270, -0.1205, -0.2122,  0.0705,\n",
      "         -0.1157,  0.0162]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20,256)\n",
    "        self.out = nn.Linear(256,10)\n",
    "    def forward(self,X):\n",
    "        return self.out(F.relu(self.hidden(X)))\n",
    "\n",
    "net = MLP()\n",
    "print(net(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1434, -0.0026, -0.1779, -0.2177, -0.0589,  0.1496,  0.0689, -0.1030,\n",
      "          0.0693,  0.3950],\n",
      "        [-0.1458,  0.0294, -0.0035, -0.0575, -0.0343,  0.0650,  0.0564, -0.1525,\n",
      "          0.0467,  0.4029]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class MySequential(nn.Module):\n",
    "    def __init__(self, *args) -> None:\n",
    "        super().__init__()\n",
    "        for indexid,module in enumerate(args):\n",
    "            self._modules[str(indexid)] = module\n",
    "    def forward(self,X):\n",
    "        for module in self._modules.values():\n",
    "            X = module(X)\n",
    "        return X\n",
    "net = MySequential(nn.Linear(20,256),nn.ReLU(),nn.Linear(256,10))\n",
    "print(net(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0336, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class FixedHiddenMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fixed_weight = torch.rand(20,20,requires_grad=False)\n",
    "        self.line = nn.Linear(20,20)\n",
    "    def forward(self,X):\n",
    "        X = self.line(X)\n",
    "        X = torch.mm(X,self.fixed_weight)+1\n",
    "        X = self.line(X)\n",
    "        while(X.abs().sum()>1):\n",
    "            X = X/2\n",
    "        return X.sum()\n",
    "\n",
    "net = FixedHiddenMLP()\n",
    "print(net(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3501, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NestMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(20,64),nn.ReLU(),nn.Linear(64,32))\n",
    "        self.linear = nn.Linear(32,16)\n",
    "    def forward(self,X):\n",
    "        return self.linear(self.net(X))\n",
    "\n",
    "net = nn.Sequential(NestMLP(),nn.Linear(16,20),FixedHiddenMLP())\n",
    "net(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数管理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat2 must be a matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m a \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([[\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m],[\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m]])\n\u001b[0;32m      3\u001b[0m b \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m])\n\u001b[1;32m----> 4\u001b[0m \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39;49mmm(a,b))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat2 must be a matrix"
     ]
    }
   ],
   "source": [
    "# test \n",
    "a = torch.tensor([[1,2,3],[1,2,3]])\n",
    "b = torch.tensor([1,2,3])\n",
    "print(torch.mm(a,b))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(*[(name, param.shape) for name, param in net.named_parameters()]),这句代码中的*号是什么意思\n",
    "\n",
    "在Python中，*符号可以用来解包一个序列或可迭代对象。在这个例子中，*号将一个元组列表解包成了一个由多个元组组成的参数列表，然后将其传递给print()函数。这样做的效果是将每个元组作为单独的参数传递给print()函数，从而使输出更加易读。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (block 0): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): Linear(in_features=8, out_features=4, bias=True)\n",
      "    )\n",
      "    (block 1): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): Linear(in_features=8, out_features=4, bias=True)\n",
      "    )\n",
      "    (block 2): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): Linear(in_features=8, out_features=4, bias=True)\n",
      "    )\n",
      "    (block 3): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): Linear(in_features=8, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# class Block1(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.net = nn.Sequential(nn.Linear(4,8),nn.Linear(8,4))\n",
    "#     def forward(self,X):\n",
    "#         return self.net(X)\n",
    "\n",
    "def block1():\n",
    "    return nn.Sequential(nn.Linear(4,8),nn.Linear(8,4))\n",
    "\n",
    "# class Block2(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.net = nn.Sequential()\n",
    "#         for i in range(4):\n",
    "#             self.net.add_module(f'block {i}',block1())\n",
    "#     def forward(self,X):\n",
    "#         return self.net(X)\n",
    "def block2():\n",
    "    net = nn.Sequential()\n",
    "    for i in range(4):\n",
    "        net.add_module(f'block {i}',block1())\n",
    "    return net\n",
    "\n",
    "wgnet = nn.Sequential(block2(),nn.Linear(4,1))\n",
    "print(wgnet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2439],\n",
      "        [-0.2435]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(2,4)\n",
    "print(wgnet(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3983,  0.1915,  0.0086, -0.4750,  0.0407,  0.0755, -0.0124, -0.3499])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wgnet[0][1][0].bias.data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "tensor([0., 0., 0., 0.])\n",
      "tensor([[37.2525],\n",
      "        [41.9075],\n",
      "        [43.4474],\n",
      "        [42.0509],\n",
      "        [37.6657],\n",
      "        [38.6354],\n",
      "        [38.9725],\n",
      "        [35.1170],\n",
      "        [33.6378],\n",
      "        [46.2599]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def parameter_init_normal(m):\n",
    "    if(type(m)==nn.Linear):\n",
    "        nn.init.normal_(m.weight,mean=0,std=0.01)\n",
    "        nn.init.zeros_(m.bias)\n",
    "def parameter_init_constant(m):\n",
    "    if(type(m)==nn.Linear):\n",
    "        nn.init.constant_(m.weight,1)\n",
    "        nn.init.zeros_(m.bias)\n",
    "net = nn.Sequential(nn.Linear(20,4),nn.ReLU(),nn.Linear(4,1))\n",
    "net.apply(parameter_init_constant)\n",
    "print(net[0].weight.data[0])\n",
    "print(net[0].bias.data)\n",
    "X = torch.rand(10,20)\n",
    "print(net(X))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1959, -0.4714,  0.1382,  0.3327,  0.2914, -0.4969, -0.3284, -0.1302,\n",
      "        -0.3640,  0.2145,  0.1068,  0.4011,  0.2599, -0.4051, -0.1244, -0.1086,\n",
      "        -0.1508,  0.4982, -0.0287,  0.3347])\n",
      "tensor([[42., 42., 42., 42.]])\n"
     ]
    }
   ],
   "source": [
    "def xavier(m):\n",
    "    if(type(m)==nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "def init_42(m):\n",
    "    if(type(m)==nn.Linear):\n",
    "        nn.init.constant_(m.weight,42)\n",
    "net[0].apply(xavier)\n",
    "net[2].apply(init_42)\n",
    "print(net[0].weight.data[0])\n",
    "print(net[2].weight.data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⾃定义初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now Initing: weight torch.Size([4, 20])\n",
      "tensor([-0.0000,  7.6048, -5.1895, -9.8662, -0.0000,  0.0000,  0.0000,  8.9224,\n",
      "        -8.3338,  8.3607,  8.9415, -9.4858,  6.4705,  0.0000, -0.0000,  0.0000,\n",
      "         8.0651, -0.0000, -9.2468,  0.0000])\n"
     ]
    }
   ],
   "source": [
    "def my_init(m):\n",
    "    if(type(m)==nn.Linear):\n",
    "        print('now Initing:',*[(name,param.shape) for name,param in m.named_parameters()][0] )\n",
    "        nn.init.uniform_(m.weight,-10,10)\n",
    "        m.weight.data *= m.weight.data.abs() >=5\n",
    "net[0].apply(my_init)\n",
    "print(net[0].weight.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([42.0000,  8.6048, -4.1895, -8.8662,  1.0000,  1.0000,  1.0000,  9.9224,\n",
      "        -7.3338,  9.3607,  9.9415, -8.4858,  7.4705,  1.0000,  1.0000,  1.0000,\n",
      "         9.0651,  1.0000, -8.2468,  1.0000])\n"
     ]
    }
   ],
   "source": [
    "# 直接设置参数\n",
    "net[0].weight.data +=1 \n",
    "net[0].weight.data[0,0] =42\n",
    "print(net[0].weight.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0863],\n",
      "        [0.0911],\n",
      "        [0.0949],\n",
      "        [0.1009],\n",
      "        [0.0925],\n",
      "        [0.0901],\n",
      "        [0.0872],\n",
      "        [0.0937],\n",
      "        [0.0884],\n",
      "        [0.0840]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "shared = nn.Linear(8,8)\n",
    "net = nn.Sequential(nn.Linear(4,8),nn.ReLU(),shared,nn.ReLU(),shared,nn.ReLU(),nn.Linear(8,1))\n",
    "X = torch.rand(10,4)\n",
    "print(net(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].weight.data[0] == net[4].weight.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].weight.data[0] +=1\n",
    "net[2].weight.data[0] == net[4].weight.data[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不带参数的层 自定义层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2., -1.,  0.,  1.,  2.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CenteredLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self,X):\n",
    "        return X - X.mean()\n",
    "    \n",
    "centered_layer = CenteredLayer()\n",
    "centered_layer(torch.FloatTensor([1,2,3,4,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.0955e-09, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(nn.Linear(8,128),CenteredLayer())\n",
    "X = torch.rand(4,8)\n",
    "net(X).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0334, -0.9891, -0.7508,  1.0393],\n",
      "        [ 0.9010,  0.6360, -0.8480, -0.1904],\n",
      "        [ 1.0690, -0.8615,  0.0803, -1.0801],\n",
      "        [ 0.2910, -1.4121,  1.4311, -0.3681],\n",
      "        [ 0.7326, -0.1772, -0.0719,  0.0794],\n",
      "        [-0.3534, -0.0235, -2.6597,  0.1482],\n",
      "        [ 0.8656, -0.5322,  1.5258, -0.2301],\n",
      "        [-1.5393,  0.4759, -0.1086,  0.6218],\n",
      "        [ 0.6162, -0.7912,  0.9437, -0.0983],\n",
      "        [-0.7819, -0.6871,  0.2163, -1.2243],\n",
      "        [ 0.7624,  1.7866,  0.4706,  0.3238],\n",
      "        [-0.1634, -0.1359, -0.1154,  0.7761]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "## 带参数的层\n",
    "class MyLinear(nn.Module):\n",
    "    def __init__(self,input_n,output_n):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(input_n,output_n))\n",
    "        self.bias = nn.Parameter(torch.zeros(output_n))\n",
    "    def forward(self,X):\n",
    "        linear = torch.mm(X,self.weight.data)+self.bias.data\n",
    "        return F.relu(linear)\n",
    "\n",
    "linear = MyLinear(12,4)\n",
    "print(linear.weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1164, 0.0000, 0.0000, 0.6667],\n",
       "        [1.7693, 0.0000, 0.5816, 0.0000],\n",
       "        [0.9837, 0.0000, 0.0000, 0.8493]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(torch.rand(3,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4602],\n",
       "        [0.0000],\n",
       "        [0.0000]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(MyLinear(8,19),MyLinear(19,1))\n",
    "net(torch.rand(3,8))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读写文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "\n",
    "a = torch.tensor([1,2,3])\n",
    "torch.save(a,'a-file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = torch.load('a-file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.tensor([2,3,4])\n",
    "c = (a,b)\n",
    "cc =[a,b]\n",
    "ccc = {'a':a,'b':b}\n",
    "torch.save(c,'c-file')\n",
    "torch.save(cc,'cc-file')\n",
    "torch.save(ccc,'ccc-file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([1, 2, 3]), tensor([2, 3, 4]))\n",
      "[tensor([1, 2, 3]), tensor([2, 3, 4])]\n",
      "{'a': tensor([1, 2, 3]), 'b': tensor([2, 3, 4])}\n"
     ]
    }
   ],
   "source": [
    "c2 = torch.load('c-file')\n",
    "c3 = torch.load('cc-file')\n",
    "c4 = torch.load('ccc-file')\n",
    "print(c2)\n",
    "print(c3)\n",
    "print(c4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-6.5696e-02, -3.1831e-01, -2.2090e-01,  2.7626e-01,  9.6878e-02,\n",
      "          1.5350e-01, -1.9059e-01,  4.5661e-01, -3.0889e-02,  1.1137e-01],\n",
      "        [ 6.7214e-05, -3.8045e-01, -1.4539e-01,  2.6692e-01,  1.4782e-01,\n",
      "          4.3826e-01, -2.1198e-02,  2.7450e-01, -8.1349e-02,  3.5255e-02]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 存储整个模型的参数\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(10,20)\n",
    "        self.output = nn.Linear(20,10)\n",
    "    def forward(self,X):\n",
    "        return self.output(F.relu(self.hidden(X)))\n",
    "net = MLP()\n",
    "X = torch.rand(2,10)\n",
    "print(net(X))\n",
    "torch.save(net.state_dict(),'net_params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.5696e-02, -3.1831e-01, -2.2090e-01,  2.7626e-01,  9.6878e-02,\n",
       "          1.5350e-01, -1.9059e-01,  4.5661e-01, -3.0889e-02,  1.1137e-01],\n",
       "        [ 6.7214e-05, -3.8045e-01, -1.4539e-01,  2.6692e-01,  1.4782e-01,\n",
       "          4.3826e-01, -2.1198e-02,  2.7450e-01, -8.1349e-02,  3.5255e-02]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2 = MLP()\n",
    "net2.load_state_dict(torch.load('net_params'))\n",
    "net2.eval()\n",
    "net2(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2(X)==net(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cpu'), device(type='cpu'), [device(type='cpu')])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def try_GPU(i=0):\n",
    "    if(torch.cuda.device_count()>=i+1):\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')\n",
    "def try_all_GPU():\n",
    "    devices = [torch.device(f'cuda:{i}') for i in range(torch.cuda.device_count())]\n",
    "    return devices if devices else [torch.device('cpu')]\n",
    "try_GPU(),try_GPU(10),try_all_GPU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3])\n",
    "x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3],device=try_GPU())\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.tensor([1,2,3],device=try_GPU(1))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m z \u001b[39m=\u001b[39m a\u001b[39m.\u001b[39;49mcuda(\u001b[39m1\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m b\u001b[39m+\u001b[39mz\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\cuda\\__init__.py:239\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    236\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    237\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    238\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m'\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 239\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    240\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    241\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[0;32m    242\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "z = a.cuda(1)\n",
    "b+z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=3, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(nn.Linear(3,1))\n",
    "net.to(try_GPU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=3, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
